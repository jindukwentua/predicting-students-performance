{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing python libraries\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set(style = 'darkgrid')\n",
    "import requests\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import export_graphviz \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = pd.read_csv('../data/student-mat.csv', sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode final_grade\n",
    "le = preprocessing.LabelEncoder()\n",
    "student_data.final_grade = le.fit_transform(data.final_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target columns from the predictive features\n",
    "X = student_data.drop(labels=['final_grade','final_score'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target variable\n",
    "y = student_data.final_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy varibles for the predictive features\n",
    "X = pd.get_dummies(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and configure the model\n",
    "# l1 regularization gives better results\n",
    "model = LogisticRegression()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "preds = model.predict(X_test)\n",
    "print('Accuracy : ',accuracy_score(y_test, preds))\n",
    "\n",
    "print(f'The accuracy score is: {accuracy_score(y_test, preds)} and the f1 score is {f1_score(y_test, preds)}')\n",
    "print(f'The recall score is: {recall_score(y_test, preds)}')\n",
    "print('\\n')\n",
    "print(f'{classification_report(y_test, preds)}')\n",
    "matrix = confusion_matrix(y_test, preds)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matrix,annot = True, fmt = \"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define and configure the model\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "preds = model.predict(X_test)\n",
    "print('Accuracy : ',accuracy_score(y_test, preds))\n",
    "\n",
    "print(f'The accuracy score is: {accuracy_score(y_test, preds)} and the f1 score is {f1_score(y_test, preds)}')\n",
    "print(f'The recall score is: {recall_score(y_test, preds)}')\n",
    "print('\\n')\n",
    "print(f'{classification_report(y_test, preds)}')\n",
    "matrix = confusion_matrix(y_test, preds)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matrix,annot = True, fmt = \"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and configure the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "preds = model.predict(X_test)\n",
    "print('Accuracy : ',accuracy_score(y_test, preds))\n",
    "\n",
    "print(f'The accuracy score is: {accuracy_score(y_test, preds)} and the f1 score is {f1_score(y_test, preds)}')\n",
    "print(f'The recall score is: {recall_score(y_test, preds)}')\n",
    "print('\\n')\n",
    "print(f'{classification_report(y_test, preds)}')\n",
    "matrix = confusion_matrix(y_test, preds)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matrix,annot = True, fmt = \"d\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
